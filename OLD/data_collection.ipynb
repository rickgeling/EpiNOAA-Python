{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2924ec3",
   "metadata": {},
   "source": [
    "# Load Libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4120b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c866ddb",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b81219",
   "metadata": {},
   "source": [
    "### Put the Crop Yield & Weather data in appropriate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895f725",
   "metadata": {},
   "source": [
    "#### Crop yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c07076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corn Yield DataFrame:\n",
      "    year  state_ansi  county_ansi  district_code  \\\n",
      "0  2023          17          NaN             99   \n",
      "1  2023          17        107.0             40   \n",
      "2  2023          17        115.0             40   \n",
      "3  2023          17        125.0             40   \n",
      "4  2023          17        113.0             40   \n",
      "\n",
      "                                    data_item  value   cv  \n",
      "0  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  208.5  1.0  \n",
      "1  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  211.1  1.6  \n",
      "2  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  225.3  2.8  \n",
      "3  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  208.1  3.6  \n",
      "4  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  223.3  2.2  \n",
      "\n",
      "Unique Data Items in the corn yield data:\n",
      "['CORN, GRAIN - YIELD, MEASURED IN BU / ACRE'\n",
      " 'CORN, GRAIN, IRRIGATED - YIELD, MEASURED IN BU / ACRE'\n",
      " 'CORN, GRAIN, NON-IRRIGATED - YIELD, MEASURED IN BU / ACRE']\n"
     ]
    }
   ],
   "source": [
    "# 1) Read the corn yield CSV into a pandas DataFrame\n",
    "path_raw = \"../02_data/corn_belt_2024_thesis/raw_data/\"\n",
    "file_name = \"240917_corn_yield_data.csv\"\n",
    "\n",
    "full_path = os.path.join(path_raw, file_name)\n",
    "df_corn_yield = pd.read_csv(full_path)\n",
    "\n",
    "# 2) Select only the columns we care about:\n",
    "df_corn_yield = df_corn_yield[\n",
    "    [\"Year\", \"State ANSI\", \"County ANSI\", \"Ag District Code\", \"Data Item\", \"Value\", \"CV (%)\"]\n",
    "]\n",
    "\n",
    "#3) Rename the columns to your preferred naming:\n",
    "df_corn_yield.columns = [\"year\", \"state_ansi\", \"county_ansi\", \"district_code\", \"data_item\", \"value\", \"cv\"]\n",
    "\n",
    "#orint the corn yield DataFrame sample\n",
    "print(\"Corn Yield DataFrame:\\n\", df_corn_yield.head())\n",
    "\n",
    "#print all unique items in the Data Item column ;)\n",
    "unique_data_items = df_corn_yield[\"data_item\"].unique()\n",
    "print(\"\\nUnique Data Items in the corn yield data:\")\n",
    "print(unique_data_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991eebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  state_ansi county_ansi district_code\n",
      "1  2023          17         107            04\n",
      "2  2023          17         115            04\n",
      "3  2023          17         125            04\n",
      "4  2023          17         113            04\n",
      "5  2023          17         129            04\n"
     ]
    }
   ],
   "source": [
    "# ADJUST THE CORN YIELD DATA TO ALIGN WITH THE WEATHER DATA\n",
    "#remove '99' districts\n",
    "df_corn_yield = df_corn_yield[df_corn_yield[\"district_code\"] != \"99\"]\n",
    "\n",
    "#drop rows where county_ansi is NaN (prevents IntCastingNaNError)\n",
    "df_corn_yield = df_corn_yield.dropna(subset=[\"county_ansi\"])\n",
    "\n",
    "#convert county_ansi to int\n",
    "df_corn_yield[\"county_ansi\"] = df_corn_yield[\"county_ansi\"].astype(int)\n",
    "\n",
    "#(Optional) Convert county_ansi back to a zero-padded string (3 digits) to match NOAA if needed\n",
    "df_corn_yield[\"county_ansi\"] = df_corn_yield[\"county_ansi\"].astype(str).str.zfill(3)\n",
    "\n",
    "#reverse district_code if you need \"10\" → \"01\" for matching NOAA divisions\n",
    "df_corn_yield[\"district_code\"] = df_corn_yield[\"district_code\"].apply(\n",
    "    lambda x: str(x)[::-1].zfill(2)\n",
    ")\n",
    "\n",
    "print(df_corn_yield[[\"year\", \"state_ansi\", \"county_ansi\", \"district_code\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0364a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year ranges per state:\n",
      "             min   max\n",
      "state_ansi            \n",
      "17          1925  2023\n",
      "19          1926  2023\n",
      "27          1921  2023\n",
      "31          1918  2023\n",
      "Highest minimum year across states: 1926\n",
      "Lowest maximum year across states: 2023\n"
     ]
    }
   ],
   "source": [
    "# Compute the min and max year for each state in the corn yield dataset\n",
    "state_year_ranges = df_corn_yield.groupby(\"state_ansi\")[\"year\"].agg([\"min\", \"max\"])\n",
    "print(\"Year ranges per state:\")\n",
    "print(state_year_ranges)\n",
    "\n",
    "# Get the highest minimum year (i.e. the maximum of the minimum years)\n",
    "highest_min_year = state_year_ranges[\"min\"].max()\n",
    "\n",
    "# Get the lowest maximum year (i.e. the minimum of the maximum years)\n",
    "lowest_max_year = state_year_ranges[\"max\"].min()\n",
    "\n",
    "print(f\"Highest minimum year across states: {highest_min_year}\")\n",
    "print(f\"Lowest maximum year across states: {lowest_max_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36462781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted DataFrame:\n",
      "   year  state_ansi county_ansi district_code  \\\n",
      "1  2023          17         107            04   \n",
      "2  2023          17         115            04   \n",
      "3  2023          17         125            04   \n",
      "4  2023          17         113            04   \n",
      "5  2023          17         129            04   \n",
      "\n",
      "                                    data_item  value   cv  \n",
      "1  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  211.1  1.6  \n",
      "2  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  225.3  2.8  \n",
      "3  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  208.1  3.6  \n",
      "4  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  223.3  2.2  \n",
      "5  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  214.4  3.9  \n"
     ]
    }
   ],
   "source": [
    "# Assuming df_corn_yield is your DataFrame and highest_min_year and lowest_max_year have been computed\n",
    "df_adjusted = df_corn_yield[\n",
    "    (df_corn_yield[\"year\"] >= highest_min_year) &\n",
    "    (df_corn_yield[\"year\"] <= lowest_max_year)\n",
    "].copy()\n",
    "\n",
    "print(\"Adjusted DataFrame:\")\n",
    "print(df_adjusted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ddbd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest year found in df_adjusted: 1926\n"
     ]
    }
   ],
   "source": [
    "lowest_year = df_adjusted[\"year\"].min()\n",
    "print(\"Lowest year found in df_adjusted:\", lowest_year)\n",
    "\n",
    "df_corn_yield = df_adjusted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c329a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Corn Yield DataFrame:\n",
      "   year  state_ansi county_ansi district_code  \\\n",
      "1  2023          17         107            04   \n",
      "2  2023          17         115            04   \n",
      "3  2023          17         125            04   \n",
      "4  2023          17         113            04   \n",
      "5  2023          17         129            04   \n",
      "\n",
      "                                    data_item  value   cv  \n",
      "1  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  211.1  1.6  \n",
      "2  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  225.3  2.8  \n",
      "3  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  208.1  3.6  \n",
      "4  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  223.3  2.2  \n",
      "5  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE  214.4  3.9  \n"
     ]
    }
   ],
   "source": [
    "corn_yield_df = df_corn_yield[df_corn_yield[\"data_item\"] == \"CORN, GRAIN - YIELD, MEASURED IN BU / ACRE\"]\n",
    "print(\"Filtered Corn Yield DataFrame:\")\n",
    "print(corn_yield_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888806a1",
   "metadata": {},
   "source": [
    "#### Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc074b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMAX DataFrame:\n",
      "       raw_code state county division  year    Jan    Feb    Mar    Apr    May  \\\n",
      "0  01001271895    01    001       03  1895  53.70  48.70  67.60  76.40  81.90   \n",
      "1  01001271896    01    001       03  1896  54.20  60.80  65.30  81.60  88.50   \n",
      "2  01001271897    01    001       03  1897  54.20  63.10  71.40  75.10  83.20   \n",
      "3  01001271898    01    001       03  1898  60.60  59.10  71.00  72.00  89.50   \n",
      "4  01001271899    01    001       03  1899  55.60  53.40  68.80  73.40  89.30   \n",
      "\n",
      "     Jun    Jul    Aug    Sep    Oct    Nov    Dec  \n",
      "0  89.20  91.10  90.40  90.90  76.00  66.60  58.00  \n",
      "1  88.20  92.00  94.50  90.80  77.20  69.90  58.70  \n",
      "2  95.60  93.30  89.90  88.90  81.30  68.10  58.80  \n",
      "3  93.90  91.50  88.80  86.70  73.60  61.70  55.70  \n",
      "4  93.70  92.20  92.60  87.50  78.40  68.10  56.60  \n",
      "PCPN DataFrame:\n",
      "       raw_code state county division  year   Jan   Feb    Mar   Apr   May  \\\n",
      "0  01001011895    01    001       03  1895  7.03  2.96   8.36  3.53  3.96   \n",
      "1  01001011896    01    001       03  1896  5.86  5.42   5.54  3.98  3.77   \n",
      "2  01001011897    01    001       03  1897  3.27  6.63  10.94  4.35  0.81   \n",
      "3  01001011898    01    001       03  1898  2.33  2.07   2.60  4.56  0.54   \n",
      "4  01001011899    01    001       03  1899  5.80  6.94   3.35  2.22  2.93   \n",
      "\n",
      "    Jun   Jul   Aug   Sep   Oct   Nov   Dec  \n",
      "0  5.40  3.92  3.36  0.73  2.03  1.44  3.66  \n",
      "1  6.24  4.38  2.57  0.82  1.66  2.89  1.94  \n",
      "2  1.57  3.96  5.02  0.87  0.75  1.84  4.38  \n",
      "3  3.13  5.80  6.02  1.51  3.21  6.66  3.91  \n",
      "4  2.31  6.80  2.90  0.63  3.02  1.98  5.25  \n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# 1) Read the county-to-climdivs mapping file into a lookup dict\n",
    "#    The file has 3 columns (POSTAL_FIPS_ID, NCDC_FIPS_ID, CLIMDIV_ID)\n",
    "#    We'll map NCDC_FIPS_ID -> (POSTAL_FIPS_ID, CLIMDIV_ID)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "mapping = {}\n",
    "with open(os.path.join(path_raw, \"county-to-climdivs.txt\"), \"r\") as f:\n",
    "    next(f)  # skip header line if it exists\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        postal_fips, ncdc_fips, climdiv_id = parts\n",
    "        mapping[ncdc_fips] = (postal_fips, climdiv_id)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#2) Define a helper function to parse each line in tmaxcy/pcpncy\n",
    "# -----------------------------------------------------------------\n",
    "def parse_clim_line(line):\n",
    "    \"\"\"\n",
    "    Given a line (string) from tmaxcy or pcpncy,\n",
    "    returns a dict with raw_code, state, county, division, year, and the 12 monthly values.\n",
    "    If the line can't be mapped (NCDC FIPS not found), return None.\n",
    "    \"\"\"\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) < 13:\n",
    "        return None  # not enough data\n",
    "    \n",
    "    # The first item is the 11-digit code: e.g. \"01001271895\"\n",
    "    code = parts[0]\n",
    "    monthly_values = parts[1:]  # the next 12 numbers\n",
    "    \n",
    "    ncdc_fips = code[:5]       #first 5 digits\n",
    "    data_type = code[5:7]      #next 2 digits (27 for tmax, 01 for pcpn)\n",
    "    year = code[7:]            #last 4 digits\n",
    "    \n",
    "    if ncdc_fips not in mapping:\n",
    "        return None\n",
    "    \n",
    "    postal_fips, climdiv_id = mapping[ncdc_fips]\n",
    "    # postal_fips e.g. \"04001\" => correct_state=\"04\", correct_county=\"001\"\n",
    "    correct_state = postal_fips[:2]\n",
    "    correct_county = postal_fips[2:]\n",
    "    # climdiv_id e.g. \"0202\" => last two digits \"02\" for division\n",
    "    division = climdiv_id[-2:]\n",
    "    \n",
    "    # Create a dict with the data, including the raw_code for clarity\n",
    "    return {\n",
    "        \"raw_code\": code,\n",
    "        \"state\": correct_state,\n",
    "        \"county\": correct_county,\n",
    "        \"division\": division,\n",
    "        \"year\": year,\n",
    "        \"Jan\": monthly_values[0],\n",
    "        \"Feb\": monthly_values[1],\n",
    "        \"Mar\": monthly_values[2],\n",
    "        \"Apr\": monthly_values[3],\n",
    "        \"May\": monthly_values[4],\n",
    "        \"Jun\": monthly_values[5],\n",
    "        \"Jul\": monthly_values[6],\n",
    "        \"Aug\": monthly_values[7],\n",
    "        \"Sep\": monthly_values[8],\n",
    "        \"Oct\": monthly_values[9],\n",
    "        \"Nov\": monthly_values[10],\n",
    "        \"Dec\": monthly_values[11]\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#3) Read & parse tmaxcy (temperature) lines\n",
    "# -----------------------------------------------------------------\n",
    "tmax_records = []\n",
    "with open(os.path.join(path_raw, \"240924 climdiv-tmaxcy-v1.0.0-20240906.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        parsed = parse_clim_line(line)\n",
    "        if parsed:\n",
    "            tmax_records.append(parsed)\n",
    "\n",
    "df_tmax = pd.DataFrame(tmax_records)\n",
    "print(\"TMAX DataFrame:\\n\", df_tmax.head())\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#4) Lastly Read & parse pcpncy (precipitation) lines\n",
    "# -----------------------------------------------------------------\n",
    "pcpn_records = []\n",
    "with open(os.path.join(path_raw, \"240924 climdiv-pcpncy-v1.0.0-20240906.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        parsed = parse_clim_line(line)\n",
    "        if parsed:\n",
    "            pcpn_records.append(parsed)\n",
    "\n",
    "df_pcpn = pd.DataFrame(pcpn_records)\n",
    "print(\"PCPN DataFrame:\\n\", df_pcpn.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a6ada",
   "metadata": {},
   "source": [
    "### Check for missing data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24dbc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Temperature Data (per month):\n",
      "Series([], dtype: float64)\n",
      "\n",
      "Missing values in Precipitation Data (per month):\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data in temperature and precipitation DataFrames\n",
    "#identify monthly columns by suffix in temperature and precipitation DataFrames\n",
    "tmax_months = [col for col in df_tmax.columns if col.endswith(\"_tmax\")]\n",
    "pcpn_months = [col for col in df_pcpn.columns if col.endswith(\"_pcpn\")]\n",
    "\n",
    "#count missing values in temperature data (-99.99 indicates missing)\n",
    "missing_tmax = (df_tmax[tmax_months] == -99.99).sum()\n",
    "print(\"Missing values in Temperature Data (per month):\")\n",
    "print(missing_tmax)\n",
    "\n",
    "#count missing values in precipitation data (-9.99 indicates missing)\n",
    "missing_pcpn = (df_pcpn[pcpn_months] == -9.99).sum()\n",
    "print(\"\\nMissing values in Precipitation Data (per month):\")\n",
    "print(missing_pcpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "764d3d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Temperature DataFrame States: ['17' '19' '27' '31']\n",
      "Filtered Precipitation DataFrame States: ['17' '19' '27' '31']\n"
     ]
    }
   ],
   "source": [
    "# Filter the temperature and precipitation DataFrames to include only states in the corn yield data\n",
    "# Here we reuse the unique_states from the crop yield DataFrame as the allowed state list\n",
    "allowed_states = df_corn_yield[\"state_ansi\"].astype(str).unique()\n",
    "\n",
    "df_tmax = df_tmax[df_tmax[\"state\"].isin(allowed_states)]\n",
    "df_pcpn = df_pcpn[df_pcpn[\"state\"].isin(allowed_states)]\n",
    "\n",
    "print(\"Filtered Temperature DataFrame States:\", df_tmax[\"state\"].unique())\n",
    "print(\"Filtered Precipitation DataFrame States:\", df_pcpn[\"state\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8bdbe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counties per state in df_tmax:\n",
      "state\n",
      "17    102\n",
      "19     99\n",
      "27     87\n",
      "31     93\n",
      "Name: county, dtype: int64\n",
      "\n",
      "Unique counties per state in df_corn_yield:\n",
      "state_ansi\n",
      "17    102\n",
      "19     99\n",
      "27     85\n",
      "31     93\n",
      "Name: county_ansi, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count unique counties per state in the temperature DataFrame:\n",
    "tmax_counties_per_state = df_tmax.groupby('state')['county'].nunique()\n",
    "print(\"Unique counties per state in df_tmax:\")\n",
    "print(tmax_counties_per_state)\n",
    "\n",
    "# Count unique counties per state in the corn yield DataFrame:\n",
    "corn_counties_per_state = df_corn_yield.groupby('state_ansi')['county_ansi'].nunique()\n",
    "print(\"\\nUnique counties per state in df_corn_yield:\")\n",
    "print(corn_counties_per_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2bf9393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickg\\AppData\\Local\\Temp\\ipykernel_2032\\2895481728.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corn_yield_df[\"value\"] = pd.to_numeric(corn_yield_df[\"value\"], errors=\"coerce\")\n",
      "C:\\Users\\rickg\\AppData\\Local\\Temp\\ipykernel_2032\\2895481728.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corn_yield_df[\"year\"] = corn_yield_df[\"year\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield data covers years 1926 to 2023\n",
      "State 17, County 001:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 003:\n",
      "  Rows missing for years: [2012, 2013, 2015, 2021, 2023]\n",
      "State 17, County 005:\n",
      "  Rows missing for years: [2013, 2016, 2018]\n",
      "State 17, County 007:\n",
      "  Rows missing for years: [2012]\n",
      "State 17, County 009:\n",
      "  Rows missing for years: [2019]\n",
      "State 17, County 013:\n",
      "  Rows missing for years: [2013, 2016, 2018]\n",
      "State 17, County 023:\n",
      "  Rows missing for years: [2013, 2016, 2019]\n",
      "State 17, County 025:\n",
      "  Rows missing for years: [2012]\n",
      "State 17, County 029:\n",
      "  Rows missing for years: [2016, 2022]\n",
      "State 17, County 031:\n",
      "  Rows missing for years: [2008, 2011, 2012, 2013, 2014, 2015, 2017, 2018, 2020, 2022, 2023]\n",
      "State 17, County 033:\n",
      "  Rows missing for years: [2016]\n",
      "State 17, County 035:\n",
      "  Rows missing for years: [2018, 2021]\n",
      "State 17, County 039:\n",
      "  Rows missing for years: [2013, 2019, 2023]\n",
      "State 17, County 041:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 043:\n",
      "  Rows missing for years: [2008, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2023]\n",
      "State 17, County 045:\n",
      "  Rows missing for years: [2019]\n",
      "State 17, County 047:\n",
      "  Rows missing for years: [2014, 2015, 2019]\n",
      "State 17, County 051:\n",
      "  Rows missing for years: [2018, 2022]\n",
      "State 17, County 059:\n",
      "  Rows missing for years: [2023]\n",
      "State 17, County 063:\n",
      "  Rows missing for years: [2023]\n",
      "State 17, County 065:\n",
      "  Rows missing for years: [2014, 2015, 2019, 2021, 2023]\n",
      "State 17, County 067:\n",
      "  Rows missing for years: [2019]\n",
      "State 17, County 069:\n",
      "  Rows missing for years: [2008, 2009, 2010, 2011, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2022, 2023]\n",
      "State 17, County 071:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 077:\n",
      "  Rows missing for years: [2015]\n",
      "State 17, County 079:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 081:\n",
      "  Rows missing for years: [2012]\n",
      "State 17, County 083:\n",
      "  Rows missing for years: [2018, 2021]\n",
      "State 17, County 087:\n",
      "  Rows missing for years: [2012, 2015, 2018, 2019, 2021]\n",
      "State 17, County 091:\n",
      "  Rows missing for years: [2019]\n",
      "State 17, County 093:\n",
      "  Rows missing for years: [2014, 2015]\n",
      "State 17, County 097:\n",
      "  Rows missing for years: [2010, 2011, 2012, 2018]\n",
      "State 17, County 099:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 101:\n",
      "  Rows missing for years: [2012, 2013, 2016]\n",
      "State 17, County 109:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 111:\n",
      "  Rows missing for years: [2019, 2021, 2022, 2023]\n",
      "State 17, County 123:\n",
      "  Rows missing for years: [2023]\n",
      "State 17, County 125:\n",
      "  Rows missing for years: [2018]\n",
      "State 17, County 127:\n",
      "  Rows missing for years: [2012, 2018, 2021]\n",
      "State 17, County 129:\n",
      "  Rows missing for years: [2013, 2018, 2019]\n",
      "State 17, County 131:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 137:\n",
      "  Rows missing for years: [2021]\n",
      "State 17, County 145:\n",
      "  Rows missing for years: [2019, 2021]\n",
      "State 17, County 149:\n",
      "  Rows missing for years: [2019, 2021, 2022]\n",
      "State 17, County 151:\n",
      "  Rows missing for years: [2008, 2009, 2010, 2011, 2013, 2017, 2018, 2019, 2021, 2022]\n",
      "State 17, County 153:\n",
      "  Rows missing for years: [2018]\n",
      "State 17, County 155:\n",
      "  Rows missing for years: [2012, 2019]\n",
      "State 17, County 157:\n",
      "  Rows missing for years: [2013]\n",
      "State 17, County 159:\n",
      "  Rows missing for years: [2019, 2021, 2022]\n",
      "State 17, County 161:\n",
      "  Rows missing for years: [2012, 2019]\n",
      "State 17, County 165:\n",
      "  Rows missing for years: [2019]\n",
      "State 17, County 171:\n",
      "  Rows missing for years: [2018, 2019]\n",
      "State 17, County 181:\n",
      "  Rows missing for years: [2015, 2018]\n",
      "State 17, County 183:\n",
      "  Rows missing for years: [2019]\n",
      "State 17, County 185:\n",
      "  Rows missing for years: [2018]\n",
      "State 17, County 187:\n",
      "  Rows missing for years: [2021, 2023]\n",
      "State 17, County 191:\n",
      "  Rows missing for years: [2015, 2016, 2019, 2021]\n",
      "State 17, County 197:\n",
      "  Rows missing for years: [2016, 2019]\n",
      "State 17, County 199:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 001:\n",
      "  Rows missing for years: [2021, 2023]\n",
      "State 19, County 003:\n",
      "  Rows missing for years: [2019, 2021, 2022, 2023]\n",
      "State 19, County 007:\n",
      "  Rows missing for years: [2018]\n",
      "State 19, County 013:\n",
      "  Rows missing for years: [2023]\n",
      "State 19, County 029:\n",
      "  Rows missing for years: [2023]\n",
      "State 19, County 033:\n",
      "  Rows missing for years: [2023]\n",
      "State 19, County 035:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 039:\n",
      "  Rows missing for years: [2017, 2019, 2021, 2022, 2023]\n",
      "State 19, County 051:\n",
      "  Rows missing for years: [2018]\n",
      "State 19, County 053:\n",
      "  Rows missing for years: [2017, 2019, 2021]\n",
      "State 19, County 057:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 063:\n",
      "  Rows missing for years: [2019, 2023]\n",
      "State 19, County 071:\n",
      "  Rows missing for years: [2019]\n",
      "State 19, County 077:\n",
      "  Rows missing for years: [2023]\n",
      "State 19, County 079:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 085:\n",
      "  Rows missing for years: [2019, 2021]\n",
      "State 19, County 093:\n",
      "  Rows missing for years: [2019]\n",
      "State 19, County 095:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 099:\n",
      "  Rows missing for years: [2020]\n",
      "State 19, County 103:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 105:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 109:\n",
      "  Rows missing for years: [2023]\n",
      "State 19, County 113:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 115:\n",
      "  Rows missing for years: [2023]\n",
      "State 19, County 117:\n",
      "  Rows missing for years: [2017, 2018, 2019]\n",
      "State 19, County 125:\n",
      "  Rows missing for years: [2020]\n",
      "State 19, County 127:\n",
      "  Rows missing for years: [2020]\n",
      "State 19, County 129:\n",
      "  Rows missing for years: [2015, 2018]\n",
      "State 19, County 135:\n",
      "  Rows missing for years: [2015]\n",
      "State 19, County 149:\n",
      "  Rows missing for years: [2020]\n",
      "State 19, County 151:\n",
      "  Rows missing for years: [2019]\n",
      "State 19, County 155:\n",
      "  Rows missing for years: [2018]\n",
      "State 19, County 159:\n",
      "  Rows missing for years: [2019, 2023]\n",
      "State 19, County 165:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 173:\n",
      "  Rows missing for years: [2015]\n",
      "State 19, County 175:\n",
      "  Rows missing for years: [2015]\n",
      "State 19, County 179:\n",
      "  Rows missing for years: [2018]\n",
      "State 19, County 181:\n",
      "  Rows missing for years: [2019, 2021]\n",
      "State 19, County 183:\n",
      "  Rows missing for years: [2021]\n",
      "State 19, County 185:\n",
      "  Rows missing for years: [2017, 2023]\n",
      "State 27, County 001:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1993, 1995, 1996, 1997, 1998, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2008, 2009, 2011, 2012, 2015, 2017, 2019]\n",
      "State 27, County 003:\n",
      "  Rows missing for years: [2019, 2023]\n",
      "State 27, County 005:\n",
      "  Rows missing for years: [1957, 1958, 2008, 2009, 2015, 2017]\n",
      "State 27, County 007:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1965, 1993, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2017, 2018, 2019, 2023]\n",
      "State 27, County 009:\n",
      "  Rows missing for years: [1957, 1958]\n",
      "State 27, County 017:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1965, 1972, 1973, 1974, 1975, 1985, 1987, 1989, 1990, 1993, 1994, 1999, 2004, 2005, 2006, 2007, 2008, 2009, 2011, 2014, 2015, 2019, 2020, 2021]\n",
      "State 27, County 021:\n",
      "  Rows missing for years: [1957, 1958, 2004, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2017, 2018, 2019, 2021]\n",
      "State 27, County 023:\n",
      "  Rows missing for years: [2020]\n",
      "State 27, County 027:\n",
      "  Rows missing for years: [2022]\n",
      "State 27, County 029:\n",
      "  Rows missing for years: [1957, 1958, 1959, 2004, 2009, 2013, 2014, 2015, 2016, 2017, 2018, 2022, 2023]\n",
      "State 27, County 035:\n",
      "  Rows missing for years: [1957, 1958, 2008, 2012, 2013, 2014, 2018, 2019]\n",
      "State 27, County 039:\n",
      "  Rows missing for years: [2021]\n",
      "State 27, County 041:\n",
      "  Rows missing for years: [2018, 2019, 2023]\n",
      "State 27, County 043:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 051:\n",
      "  Rows missing for years: [2018]\n",
      "State 27, County 053:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 057:\n",
      "  Rows missing for years: [1957, 1958, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2017, 2018, 2019, 2023]\n",
      "State 27, County 059:\n",
      "  Rows missing for years: [2016]\n",
      "State 27, County 061:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1965, 1986, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2023]\n",
      "State 27, County 065:\n",
      "  Rows missing for years: [1957, 1958, 2013, 2015, 2017, 2018, 2019, 2020, 2023]\n",
      "State 27, County 067:\n",
      "  Rows missing for years: [2019, 2021, 2022]\n",
      "State 27, County 069:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1965, 1980, 1993, 2004, 2005, 2009, 2010, 2011, 2013, 2014, 2015, 2021, 2022, 2023]\n",
      "State 27, County 071:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1967, 1968, 1969, 1970, 1971, 1975, 1976, 1981, 1987, 1989, 1990, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2023]\n",
      "State 27, County 073:\n",
      "  Rows missing for years: [2021, 2022]\n",
      "State 27, County 077:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1979, 1986, 1987, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 079:\n",
      "  Rows missing for years: [2019]\n",
      "State 27, County 081:\n",
      "  Rows missing for years: [2018, 2022]\n",
      "State 27, County 083:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 087:\n",
      "  Rows missing for years: [1957, 1958, 2008, 2011, 2012, 2018, 2019]\n",
      "State 27, County 089:\n",
      "  Rows missing for years: [1957, 1958, 1959, 2004, 2018]\n",
      "State 27, County 091:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 093:\n",
      "  Rows missing for years: [2018]\n",
      "State 27, County 095:\n",
      "  Rows missing for years: [1957, 1958, 2018]\n",
      "State 27, County 097:\n",
      "  Rows missing for years: [1957, 1958]\n",
      "State 27, County 099:\n",
      "  Rows missing for years: [2021]\n",
      "State 27, County 101:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 107:\n",
      "  Rows missing for years: [1957, 1958, 2018, 2019, 2022]\n",
      "State 27, County 113:\n",
      "  Rows missing for years: [1957, 1958, 1959, 2004, 2005, 2011, 2012, 2013, 2014, 2016, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 115:\n",
      "  Rows missing for years: [1957, 1958, 2016, 2017]\n",
      "State 27, County 117:\n",
      "  Rows missing for years: [2018]\n",
      "State 27, County 119:\n",
      "  Rows missing for years: [1957, 1958, 2008, 2017, 2018, 2019]\n",
      "State 27, County 123:\n",
      "  Rows missing for years: [1959, 1987, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 125:\n",
      "  Rows missing for years: [1957, 1958, 1959, 2014, 2015, 2018, 2019]\n",
      "State 27, County 131:\n",
      "  Rows missing for years: [2019]\n",
      "State 27, County 133:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 135:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1965, 1971, 1976, 2004, 2010, 2016, 2022, 2023]\n",
      "State 27, County 137:\n",
      "  Rows missing for years: [1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1970, 1971, 1972, 1973, 1974, 1976, 1977, 1978, 1979, 1981, 1986, 1987, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 139:\n",
      "  Rows missing for years: [2018, 2019]\n",
      "State 27, County 141:\n",
      "  Rows missing for years: [2018]\n",
      "State 27, County 151:\n",
      "  Rows missing for years: [2021]\n",
      "State 27, County 153:\n",
      "  Rows missing for years: [1957, 1958]\n",
      "State 27, County 157:\n",
      "  Rows missing for years: [2023]\n",
      "State 27, County 167:\n",
      "  Rows missing for years: [2018, 2019]\n",
      "State 27, County 171:\n",
      "  Rows missing for years: [2018, 2019]\n",
      "State 27, County 173:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 003:\n",
      "  Rows missing for years: [2020, 2021, 2022, 2023]\n",
      "State 31, County 005:\n",
      "  Rows missing for years: [1962, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 007:\n",
      "  Rows missing for years: [2009, 2013, 2015, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 009:\n",
      "  Rows missing for years: [2008, 2009, 2010, 2011, 2012, 2013, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 011:\n",
      "  Rows missing for years: [2021, 2023]\n",
      "State 31, County 015:\n",
      "  Rows missing for years: [2013, 2014, 2016, 2018]\n",
      "State 31, County 017:\n",
      "  Rows missing for years: [2015, 2018]\n",
      "State 31, County 019:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 025:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 031:\n",
      "  Rows missing for years: [2014, 2019, 2020, 2022, 2023]\n",
      "State 31, County 033:\n",
      "  Rows missing for years: [2009, 2013, 2015, 2016, 2017, 2018, 2019, 2021]\n",
      "State 31, County 035:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 041:\n",
      "  Rows missing for years: [2021, 2022]\n",
      "State 31, County 043:\n",
      "  Rows missing for years: [2015, 2017, 2018, 2019]\n",
      "State 31, County 045:\n",
      "  Rows missing for years: [2008, 2009, 2016, 2018, 2019, 2021, 2022, 2023]\n",
      "State 31, County 047:\n",
      "  Rows missing for years: [2017, 2021]\n",
      "State 31, County 049:\n",
      "  Rows missing for years: [2014, 2015, 2016, 2017, 2022]\n",
      "State 31, County 051:\n",
      "  Rows missing for years: [2019, 2021, 2022]\n",
      "State 31, County 055:\n",
      "  Rows missing for years: [2015, 2018]\n",
      "State 31, County 057:\n",
      "  Rows missing for years: [2019]\n",
      "State 31, County 059:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 063:\n",
      "  Rows missing for years: [2018, 2023]\n",
      "State 31, County 069:\n",
      "  Rows missing for years: [2015, 2016, 2017, 2019, 2021, 2022]\n",
      "State 31, County 073:\n",
      "  Rows missing for years: [2017, 2019]\n",
      "State 31, County 075:\n",
      "  Rows missing for years: [1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 079:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 081:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 087:\n",
      "  Rows missing for years: [2017, 2019, 2021]\n",
      "State 31, County 089:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 091:\n",
      "  Rows missing for years: [1962, 1972, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 095:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 097:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 099:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 101:\n",
      "  Rows missing for years: [2019, 2022, 2023]\n",
      "State 31, County 103:\n",
      "  Rows missing for years: [2022]\n",
      "State 31, County 105:\n",
      "  Rows missing for years: [2008, 2014, 2018, 2019, 2020, 2021, 2023]\n",
      "State 31, County 113:\n",
      "  Rows missing for years: [2021, 2022]\n",
      "State 31, County 115:\n",
      "  Rows missing for years: [2009, 2011, 2013, 2014, 2016, 2018, 2019, 2021, 2022]\n",
      "State 31, County 117:\n",
      "  Rows missing for years: [2008, 2009, 2010, 2012, 2013, 2014, 2015, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 121:\n",
      "  Rows missing for years: [2021, 2022]\n",
      "State 31, County 125:\n",
      "  Rows missing for years: [2018, 2023]\n",
      "State 31, County 129:\n",
      "  Rows missing for years: [2021, 2023]\n",
      "State 31, County 131:\n",
      "  Rows missing for years: [2023]\n",
      "State 31, County 135:\n",
      "  Rows missing for years: [2022, 2023]\n",
      "State 31, County 139:\n",
      "  Rows missing for years: [2023]\n",
      "State 31, County 143:\n",
      "  Rows missing for years: [2019, 2021]\n",
      "State 31, County 145:\n",
      "  Rows missing for years: [2017, 2018, 2023]\n",
      "State 31, County 149:\n",
      "  Rows missing for years: [2012, 2013, 2015, 2017, 2018, 2022]\n",
      "State 31, County 151:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 153:\n",
      "  Rows missing for years: [2015, 2019]\n",
      "State 31, County 155:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 159:\n",
      "  Rows missing for years: [2023]\n",
      "State 31, County 161:\n",
      "  Rows missing for years: [2019, 2022, 2023]\n",
      "State 31, County 165:\n",
      "  Rows missing for years: [2016]\n",
      "State 31, County 167:\n",
      "  Rows missing for years: [2021]\n",
      "State 31, County 171:\n",
      "  Rows missing for years: [2001, 2002, 2003, 2004, 2005, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 31, County 173:\n",
      "  Rows missing for years: [2015, 2017, 2018, 2023]\n",
      "State 31, County 175:\n",
      "  Rows missing for years: [2017]\n",
      "State 31, County 181:\n",
      "  Rows missing for years: [2017, 2019, 2021]\n",
      "State 31, County 183:\n",
      "  Rows missing for years: [2012, 2013, 2015, 2016, 2017, 2018, 2019, 2021, 2022]\n",
      "State 31, County 185:\n",
      "  Rows missing for years: [2021, 2023]\n",
      "\n",
      "Summary:\n",
      "Total counties: 379\n",
      "Counties with no missing data: 164\n",
      "Counties with exactly 1 missing year: 96\n",
      "Counties with more than 1 missing year: 119\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the yield column is numeric and that 'year' is an integer\n",
    "corn_yield_df[\"value\"] = pd.to_numeric(corn_yield_df[\"value\"], errors=\"coerce\")\n",
    "corn_yield_df[\"year\"] = corn_yield_df[\"year\"].astype(int)\n",
    "\n",
    "# Dictionary to store the missing report (keyed by (state, county_ansi))\n",
    "missing_report = {}\n",
    "\n",
    "# Group by state and county to build the missing report\n",
    "for (state, county), group in corn_yield_df.groupby([\"state_ansi\", \"county_ansi\"]):\n",
    "    # Get the years present in the group (even if the yield is NaN)\n",
    "    years_present = set(group[\"year\"].unique())\n",
    "    # Compare against the fixed expected range (from 1926 to 2023)\n",
    "    missing_rows = sorted(set(range(1926, 2023 + 1)) - years_present)\n",
    "    \n",
    "    # Find years where a row exists but the yield 'value' is NaN\n",
    "    missing_values = sorted(group.loc[group[\"value\"].isna(), \"year\"].unique())\n",
    "    \n",
    "    if missing_rows or missing_values:\n",
    "        missing_report[(state, county)] = {\n",
    "            \"missing_rows\": missing_rows,\n",
    "            \"missing_values\": missing_values\n",
    "        }\n",
    "\n",
    "# Print the missing report header\n",
    "print(\"Yield data covers years 1926 to 2023\")\n",
    "for (state, county), d in missing_report.items():\n",
    "    print(f\"State {state}, County {county}:\")\n",
    "    if d[\"missing_rows\"]:\n",
    "        print(f\"  Rows missing for years: {d['missing_rows']}\")\n",
    "    if d[\"missing_values\"]:\n",
    "        print(f\"  Years with missing yield value: {d['missing_values']}\")\n",
    "\n",
    "# Compute overall reporting counts\n",
    "all_counties = list(corn_yield_df.groupby([\"state_ansi\", \"county_ansi\"]).groups.keys())\n",
    "no_missing_count = len(all_counties) - len(missing_report)\n",
    "exactly_one_missing = 0\n",
    "more_than_one_missing = 0\n",
    "\n",
    "for rep in missing_report.values():\n",
    "    total_missing = len(rep[\"missing_rows\"]) + len(rep[\"missing_values\"])\n",
    "    if total_missing == 1:\n",
    "        exactly_one_missing += 1\n",
    "    elif total_missing > 1:\n",
    "        more_than_one_missing += 1\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total counties: {len(all_counties)}\")\n",
    "print(f\"Counties with no missing data: {no_missing_count}\")\n",
    "print(f\"Counties with exactly 1 missing year: {exactly_one_missing}\")\n",
    "print(f\"Counties with more than 1 missing year: {more_than_one_missing}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69d586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties sorted by total missing years (rows + values):\n",
      "State 31, County 075: 58 missing years\n",
      "   • Missing rows: [1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 077: 57 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1979, 1986, 1987, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 137: 54 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1970, 1971, 1972, 1973, 1974, 1976, 1977, 1978, 1979, 1981, 1986, 1987, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 071: 49 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1967, 1968, 1969, 1970, 1971, 1975, 1976, 1981, 1987, 1989, 1990, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2023]\n",
      "State 27, County 123: 37 missing years\n",
      "   • Missing rows: [1959, 1987, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 061: 35 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1965, 1986, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2023]\n",
      "State 31, County 091: 32 missing years\n",
      "   • Missing rows: [1962, 1972, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 017: 27 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1965, 1972, 1973, 1974, 1975, 1985, 1987, 1989, 1990, 1993, 1994, 1999, 2004, 2005, 2006, 2007, 2008, 2009, 2011, 2014, 2015, 2019, 2020, 2021]\n",
      "State 31, County 005: 24 missing years\n",
      "   • Missing rows: [1962, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 001: 22 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1993, 1995, 1996, 1997, 1998, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2008, 2009, 2011, 2012, 2015, 2017, 2019]\n",
      "State 31, County 171: 21 missing years\n",
      "   • Missing rows: [2001, 2002, 2003, 2004, 2005, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 007: 20 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1965, 1993, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2017, 2018, 2019, 2023]\n",
      "State 27, County 021: 17 missing years\n",
      "   • Missing rows: [1957, 1958, 2004, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2017, 2018, 2019, 2021]\n",
      "State 27, County 069: 17 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1965, 1980, 1993, 2004, 2005, 2009, 2010, 2011, 2013, 2014, 2015, 2021, 2022, 2023]\n",
      "State 27, County 113: 16 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 2004, 2005, 2011, 2012, 2013, 2014, 2016, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 17, County 043: 14 missing years\n",
      "   • Missing rows: [2008, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2023]\n",
      "State 17, County 069: 14 missing years\n",
      "   • Missing rows: [2008, 2009, 2010, 2011, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2022, 2023]\n",
      "State 27, County 057: 14 missing years\n",
      "   • Missing rows: [1957, 1958, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2017, 2018, 2019, 2023]\n",
      "State 31, County 117: 14 missing years\n",
      "   • Missing rows: [2008, 2009, 2010, 2012, 2013, 2014, 2015, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 029: 13 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 2004, 2009, 2013, 2014, 2015, 2016, 2017, 2018, 2022, 2023]\n",
      "State 31, County 009: 13 missing years\n",
      "   • Missing rows: [2008, 2009, 2010, 2011, 2012, 2013, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 17, County 031: 11 missing years\n",
      "   • Missing rows: [2008, 2011, 2012, 2013, 2014, 2015, 2017, 2018, 2020, 2022, 2023]\n",
      "State 27, County 135: 11 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 1965, 1971, 1976, 2004, 2010, 2016, 2022, 2023]\n",
      "State 17, County 151: 10 missing years\n",
      "   • Missing rows: [2008, 2009, 2010, 2011, 2013, 2017, 2018, 2019, 2021, 2022]\n",
      "State 31, County 007: 10 missing years\n",
      "   • Missing rows: [2009, 2013, 2015, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "State 27, County 065: 9 missing years\n",
      "   • Missing rows: [1957, 1958, 2013, 2015, 2017, 2018, 2019, 2020, 2023]\n",
      "State 31, County 115: 9 missing years\n",
      "   • Missing rows: [2009, 2011, 2013, 2014, 2016, 2018, 2019, 2021, 2022]\n",
      "State 31, County 183: 9 missing years\n",
      "   • Missing rows: [2012, 2013, 2015, 2016, 2017, 2018, 2019, 2021, 2022]\n",
      "State 27, County 035: 8 missing years\n",
      "   • Missing rows: [1957, 1958, 2008, 2012, 2013, 2014, 2018, 2019]\n",
      "State 31, County 033: 8 missing years\n",
      "   • Missing rows: [2009, 2013, 2015, 2016, 2017, 2018, 2019, 2021]\n",
      "State 31, County 045: 8 missing years\n",
      "   • Missing rows: [2008, 2009, 2016, 2018, 2019, 2021, 2022, 2023]\n",
      "State 27, County 087: 7 missing years\n",
      "   • Missing rows: [1957, 1958, 2008, 2011, 2012, 2018, 2019]\n",
      "State 27, County 125: 7 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 2014, 2015, 2018, 2019]\n",
      "State 31, County 105: 7 missing years\n",
      "   • Missing rows: [2008, 2014, 2018, 2019, 2020, 2021, 2023]\n",
      "State 27, County 005: 6 missing years\n",
      "   • Missing rows: [1957, 1958, 2008, 2009, 2015, 2017]\n",
      "State 27, County 119: 6 missing years\n",
      "   • Missing rows: [1957, 1958, 2008, 2017, 2018, 2019]\n",
      "State 31, County 069: 6 missing years\n",
      "   • Missing rows: [2015, 2016, 2017, 2019, 2021, 2022]\n",
      "State 31, County 149: 6 missing years\n",
      "   • Missing rows: [2012, 2013, 2015, 2017, 2018, 2022]\n",
      "State 17, County 003: 5 missing years\n",
      "   • Missing rows: [2012, 2013, 2015, 2021, 2023]\n",
      "State 17, County 065: 5 missing years\n",
      "   • Missing rows: [2014, 2015, 2019, 2021, 2023]\n",
      "State 17, County 087: 5 missing years\n",
      "   • Missing rows: [2012, 2015, 2018, 2019, 2021]\n",
      "State 19, County 039: 5 missing years\n",
      "   • Missing rows: [2017, 2019, 2021, 2022, 2023]\n",
      "State 27, County 089: 5 missing years\n",
      "   • Missing rows: [1957, 1958, 1959, 2004, 2018]\n",
      "State 27, County 107: 5 missing years\n",
      "   • Missing rows: [1957, 1958, 2018, 2019, 2022]\n",
      "State 31, County 031: 5 missing years\n",
      "   • Missing rows: [2014, 2019, 2020, 2022, 2023]\n",
      "State 31, County 049: 5 missing years\n",
      "   • Missing rows: [2014, 2015, 2016, 2017, 2022]\n",
      "State 17, County 097: 4 missing years\n",
      "   • Missing rows: [2010, 2011, 2012, 2018]\n",
      "State 17, County 111: 4 missing years\n",
      "   • Missing rows: [2019, 2021, 2022, 2023]\n",
      "State 17, County 191: 4 missing years\n",
      "   • Missing rows: [2015, 2016, 2019, 2021]\n",
      "State 19, County 003: 4 missing years\n",
      "   • Missing rows: [2019, 2021, 2022, 2023]\n",
      "State 27, County 115: 4 missing years\n",
      "   • Missing rows: [1957, 1958, 2016, 2017]\n",
      "State 31, County 003: 4 missing years\n",
      "   • Missing rows: [2020, 2021, 2022, 2023]\n",
      "State 31, County 015: 4 missing years\n",
      "   • Missing rows: [2013, 2014, 2016, 2018]\n",
      "State 31, County 043: 4 missing years\n",
      "   • Missing rows: [2015, 2017, 2018, 2019]\n",
      "State 31, County 173: 4 missing years\n",
      "   • Missing rows: [2015, 2017, 2018, 2023]\n",
      "State 17, County 005: 3 missing years\n",
      "   • Missing rows: [2013, 2016, 2018]\n",
      "State 17, County 013: 3 missing years\n",
      "   • Missing rows: [2013, 2016, 2018]\n",
      "State 17, County 023: 3 missing years\n",
      "   • Missing rows: [2013, 2016, 2019]\n",
      "State 17, County 039: 3 missing years\n",
      "   • Missing rows: [2013, 2019, 2023]\n",
      "State 17, County 047: 3 missing years\n",
      "   • Missing rows: [2014, 2015, 2019]\n",
      "State 17, County 101: 3 missing years\n",
      "   • Missing rows: [2012, 2013, 2016]\n",
      "State 17, County 127: 3 missing years\n",
      "   • Missing rows: [2012, 2018, 2021]\n",
      "State 17, County 129: 3 missing years\n",
      "   • Missing rows: [2013, 2018, 2019]\n",
      "State 17, County 149: 3 missing years\n",
      "   • Missing rows: [2019, 2021, 2022]\n",
      "State 17, County 159: 3 missing years\n",
      "   • Missing rows: [2019, 2021, 2022]\n",
      "State 19, County 053: 3 missing years\n",
      "   • Missing rows: [2017, 2019, 2021]\n",
      "State 19, County 117: 3 missing years\n",
      "   • Missing rows: [2017, 2018, 2019]\n",
      "State 27, County 041: 3 missing years\n",
      "   • Missing rows: [2018, 2019, 2023]\n",
      "State 27, County 067: 3 missing years\n",
      "   • Missing rows: [2019, 2021, 2022]\n",
      "State 27, County 095: 3 missing years\n",
      "   • Missing rows: [1957, 1958, 2018]\n",
      "State 31, County 051: 3 missing years\n",
      "   • Missing rows: [2019, 2021, 2022]\n",
      "State 31, County 087: 3 missing years\n",
      "   • Missing rows: [2017, 2019, 2021]\n",
      "State 31, County 101: 3 missing years\n",
      "   • Missing rows: [2019, 2022, 2023]\n",
      "State 31, County 145: 3 missing years\n",
      "   • Missing rows: [2017, 2018, 2023]\n",
      "State 31, County 161: 3 missing years\n",
      "   • Missing rows: [2019, 2022, 2023]\n",
      "State 31, County 181: 3 missing years\n",
      "   • Missing rows: [2017, 2019, 2021]\n",
      "State 17, County 029: 2 missing years\n",
      "   • Missing rows: [2016, 2022]\n",
      "State 17, County 035: 2 missing years\n",
      "   • Missing rows: [2018, 2021]\n",
      "State 17, County 051: 2 missing years\n",
      "   • Missing rows: [2018, 2022]\n",
      "State 17, County 083: 2 missing years\n",
      "   • Missing rows: [2018, 2021]\n",
      "State 17, County 093: 2 missing years\n",
      "   • Missing rows: [2014, 2015]\n",
      "State 17, County 145: 2 missing years\n",
      "   • Missing rows: [2019, 2021]\n",
      "State 17, County 155: 2 missing years\n",
      "   • Missing rows: [2012, 2019]\n",
      "State 17, County 161: 2 missing years\n",
      "   • Missing rows: [2012, 2019]\n",
      "State 17, County 171: 2 missing years\n",
      "   • Missing rows: [2018, 2019]\n",
      "State 17, County 181: 2 missing years\n",
      "   • Missing rows: [2015, 2018]\n",
      "State 17, County 187: 2 missing years\n",
      "   • Missing rows: [2021, 2023]\n",
      "State 17, County 197: 2 missing years\n",
      "   • Missing rows: [2016, 2019]\n",
      "State 19, County 001: 2 missing years\n",
      "   • Missing rows: [2021, 2023]\n",
      "State 19, County 063: 2 missing years\n",
      "   • Missing rows: [2019, 2023]\n",
      "State 19, County 085: 2 missing years\n",
      "   • Missing rows: [2019, 2021]\n",
      "State 19, County 129: 2 missing years\n",
      "   • Missing rows: [2015, 2018]\n",
      "State 19, County 159: 2 missing years\n",
      "   • Missing rows: [2019, 2023]\n",
      "State 19, County 181: 2 missing years\n",
      "   • Missing rows: [2019, 2021]\n",
      "State 19, County 185: 2 missing years\n",
      "   • Missing rows: [2017, 2023]\n",
      "State 27, County 003: 2 missing years\n",
      "   • Missing rows: [2019, 2023]\n",
      "State 27, County 009: 2 missing years\n",
      "   • Missing rows: [1957, 1958]\n",
      "State 27, County 073: 2 missing years\n",
      "   • Missing rows: [2021, 2022]\n",
      "State 27, County 081: 2 missing years\n",
      "   • Missing rows: [2018, 2022]\n",
      "State 27, County 097: 2 missing years\n",
      "   • Missing rows: [1957, 1958]\n",
      "State 27, County 139: 2 missing years\n",
      "   • Missing rows: [2018, 2019]\n",
      "State 27, County 153: 2 missing years\n",
      "   • Missing rows: [1957, 1958]\n",
      "State 27, County 167: 2 missing years\n",
      "   • Missing rows: [2018, 2019]\n",
      "State 27, County 171: 2 missing years\n",
      "   • Missing rows: [2018, 2019]\n",
      "State 31, County 011: 2 missing years\n",
      "   • Missing rows: [2021, 2023]\n",
      "State 31, County 017: 2 missing years\n",
      "   • Missing rows: [2015, 2018]\n",
      "State 31, County 041: 2 missing years\n",
      "   • Missing rows: [2021, 2022]\n",
      "State 31, County 047: 2 missing years\n",
      "   • Missing rows: [2017, 2021]\n",
      "State 31, County 055: 2 missing years\n",
      "   • Missing rows: [2015, 2018]\n",
      "State 31, County 063: 2 missing years\n",
      "   • Missing rows: [2018, 2023]\n",
      "State 31, County 073: 2 missing years\n",
      "   • Missing rows: [2017, 2019]\n",
      "State 31, County 113: 2 missing years\n",
      "   • Missing rows: [2021, 2022]\n",
      "State 31, County 121: 2 missing years\n",
      "   • Missing rows: [2021, 2022]\n",
      "State 31, County 125: 2 missing years\n",
      "   • Missing rows: [2018, 2023]\n",
      "State 31, County 129: 2 missing years\n",
      "   • Missing rows: [2021, 2023]\n",
      "State 31, County 135: 2 missing years\n",
      "   • Missing rows: [2022, 2023]\n",
      "State 31, County 143: 2 missing years\n",
      "   • Missing rows: [2019, 2021]\n",
      "State 31, County 153: 2 missing years\n",
      "   • Missing rows: [2015, 2019]\n",
      "State 31, County 185: 2 missing years\n",
      "   • Missing rows: [2021, 2023]\n",
      "State 17, County 001: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 007: 1 missing years\n",
      "   • Missing rows: [2012]\n",
      "State 17, County 009: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 17, County 025: 1 missing years\n",
      "   • Missing rows: [2012]\n",
      "State 17, County 033: 1 missing years\n",
      "   • Missing rows: [2016]\n",
      "State 17, County 041: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 045: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 17, County 059: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 17, County 063: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 17, County 067: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 17, County 071: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 077: 1 missing years\n",
      "   • Missing rows: [2015]\n",
      "State 17, County 079: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 081: 1 missing years\n",
      "   • Missing rows: [2012]\n",
      "State 17, County 091: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 17, County 099: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 109: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 123: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 17, County 125: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 17, County 131: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 137: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 17, County 153: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 17, County 157: 1 missing years\n",
      "   • Missing rows: [2013]\n",
      "State 17, County 165: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 17, County 183: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 17, County 185: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 17, County 199: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 007: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 19, County 013: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 19, County 029: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 19, County 033: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 19, County 035: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 051: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 19, County 057: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 071: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 19, County 077: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 19, County 079: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 093: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 19, County 095: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 099: 1 missing years\n",
      "   • Missing rows: [2020]\n",
      "State 19, County 103: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 105: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 109: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 19, County 113: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 115: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 19, County 125: 1 missing years\n",
      "   • Missing rows: [2020]\n",
      "State 19, County 127: 1 missing years\n",
      "   • Missing rows: [2020]\n",
      "State 19, County 135: 1 missing years\n",
      "   • Missing rows: [2015]\n",
      "State 19, County 149: 1 missing years\n",
      "   • Missing rows: [2020]\n",
      "State 19, County 151: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 19, County 155: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 19, County 165: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 19, County 173: 1 missing years\n",
      "   • Missing rows: [2015]\n",
      "State 19, County 175: 1 missing years\n",
      "   • Missing rows: [2015]\n",
      "State 19, County 179: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 19, County 183: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 27, County 023: 1 missing years\n",
      "   • Missing rows: [2020]\n",
      "State 27, County 027: 1 missing years\n",
      "   • Missing rows: [2022]\n",
      "State 27, County 039: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 27, County 043: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 051: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 27, County 053: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 059: 1 missing years\n",
      "   • Missing rows: [2016]\n",
      "State 27, County 079: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 27, County 083: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 091: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 093: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 27, County 099: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 27, County 101: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 117: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 27, County 131: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 27, County 133: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 141: 1 missing years\n",
      "   • Missing rows: [2018]\n",
      "State 27, County 151: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 27, County 157: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 27, County 173: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 019: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 025: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 035: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 057: 1 missing years\n",
      "   • Missing rows: [2019]\n",
      "State 31, County 059: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 079: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 081: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 089: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 095: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 097: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 099: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 103: 1 missing years\n",
      "   • Missing rows: [2022]\n",
      "State 31, County 131: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 31, County 139: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 31, County 151: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 155: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 159: 1 missing years\n",
      "   • Missing rows: [2023]\n",
      "State 31, County 165: 1 missing years\n",
      "   • Missing rows: [2016]\n",
      "State 31, County 167: 1 missing years\n",
      "   • Missing rows: [2021]\n",
      "State 31, County 175: 1 missing years\n",
      "   • Missing rows: [2017]\n"
     ]
    }
   ],
   "source": [
    "# First, build the same missing_report as before …\n",
    "# (I’ll assume you already have that dict around)\n",
    "\n",
    "# Create a list of tuples: ((state, county), total_missing)\n",
    "missing_counts = [\n",
    "    ((state, county),\n",
    "     len(d[\"missing_rows\"]) + len(d[\"missing_values\"]))\n",
    "    for (state, county), d in missing_report.items()\n",
    "]\n",
    "\n",
    "# Sort descending by total_missing\n",
    "missing_counts_sorted = sorted(\n",
    "    missing_counts,\n",
    "    key=lambda item: item[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Counties sorted by total missing years (rows + values):\")\n",
    "for (state, county), total in missing_counts_sorted:\n",
    "    d = missing_report[(state, county)]\n",
    "    rows = d[\"missing_rows\"]\n",
    "    vals = d[\"missing_values\"]\n",
    "    print(f\"State {state}, County {county}: {total} missing years\")\n",
    "    if rows:\n",
    "        print(f\"   • Missing rows: {rows}\")\n",
    "    if vals:\n",
    "        print(f\"   • Missing values: {vals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "451ed372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for \"CORN, GRAIN - YIELD, MEASURED IN BU / ACRE\" CHECK\n",
    "\n",
    "# Check for which counties years are missing in the corn yield data CHECK\n",
    "\n",
    "#Filter TMAX and precip data for years within the yield data range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb9b3d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered df_tmax:\n",
      "           raw_code state county division  year    Jan    Feb    Mar    Apr  \\\n",
      "72831   11001271926    17    001       03  1926  37.00  43.10  45.00  57.00   \n",
      "72832   11001271927    17    001       03  1927  32.80  46.10  53.90  62.00   \n",
      "72833   11001271928    17    001       03  1928  36.60  42.00  53.80  60.20   \n",
      "72834   11001271929    17    001       03  1929  29.70  31.80  56.80  64.40   \n",
      "72835   11001271930    17    001       03  1930  26.20  49.20  51.20  70.00   \n",
      "...             ...   ...    ...      ...   ...    ...    ...    ...    ...   \n",
      "222554  25185272019    31    185       06  2019  34.00  27.30  42.40  65.40   \n",
      "222555  25185272020    31    185       06  2020  33.70  41.90  53.00  63.10   \n",
      "222556  25185272021    31    185       06  2021  37.60  22.80  56.50  62.70   \n",
      "222557  25185272022    31    185       06  2022  38.40  42.00  53.40  63.80   \n",
      "222558  25185272023    31    185       06  2023  35.30  41.50  47.60  66.80   \n",
      "\n",
      "          May    Jun    Jul    Aug    Sep    Oct    Nov    Dec  \n",
      "72831   78.80  81.00  88.60  86.30  75.40  63.50  45.50  36.30  \n",
      "72832   71.60  77.90  86.40  81.80  82.60  71.10  53.40  36.90  \n",
      "72833   76.80  77.00  87.90  86.50  75.20  69.30  49.30  41.40  \n",
      "72834   70.40  81.30  87.00  85.60  76.70  66.20  44.80  38.40  \n",
      "72835   76.20  84.30  93.60  91.10  83.70  64.50  54.00  38.00  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "222554  68.40  82.00  87.10  81.90  82.00  59.30  48.20  41.20  \n",
      "222555  68.60  87.60  86.20  85.20  76.10  61.10  57.70  42.10  \n",
      "222556  71.00  87.10  85.80  87.00  82.30  67.90  55.40  48.00  \n",
      "222557  72.50  86.60  87.60  88.80  82.70  68.20  49.20  33.20  \n",
      "222558  78.70  87.20  85.20  87.80  84.40  66.60  55.40  43.60  \n",
      "\n",
      "[37338 rows x 17 columns]\n",
      "\n",
      "Filtered df_pcpn:\n",
      "           raw_code state county division  year   Jan   Feb   Mar   Apr   May  \\\n",
      "72831   11001011926    17    001       03  1926  1.32  1.98  2.61  2.98  2.15   \n",
      "72832   11001011927    17    001       03  1927  1.49  1.30  4.91  5.76  4.93   \n",
      "72833   11001011928    17    001       03  1928  0.43  1.67  1.20  3.06  2.50   \n",
      "72834   11001011929    17    001       03  1929  3.61  0.76  4.57  5.46  5.74   \n",
      "72835   11001011930    17    001       03  1930  3.31  1.41  1.20  2.04  2.27   \n",
      "...             ...   ...    ...      ...   ...   ...   ...   ...   ...   ...   \n",
      "222554  25185012019    31    185       06  2019  0.20  1.11  2.97  1.30  7.88   \n",
      "222555  25185012020    31    185       06  2020  1.22  0.07  2.29  0.98  5.05   \n",
      "222556  25185012021    31    185       06  2021  1.39  0.69  7.31  1.59  4.57   \n",
      "222557  25185012022    31    185       06  2022  0.16  0.03  1.20  2.13  5.34   \n",
      "222558  25185012023    31    185       06  2023  1.12  1.07  0.80  1.39  0.76   \n",
      "\n",
      "         Jun   Jul   Aug    Sep   Oct   Nov   Dec  \n",
      "72831   7.09  3.07  4.99  12.45  3.36  3.36  1.09  \n",
      "72832   4.64  2.90  2.43   3.16  4.69  2.94  2.48  \n",
      "72833   5.28  3.29  3.09   4.05  4.38  4.52  1.62  \n",
      "72834   5.02  6.95  2.26   3.14  4.27  1.68  0.84  \n",
      "72835   4.66  0.41  1.54   2.95  2.54  3.62  0.56  \n",
      "...      ...   ...   ...    ...   ...   ...   ...  \n",
      "222554  5.37  4.63  6.85   2.02  2.53  1.29  1.79  \n",
      "222555  2.87  5.26  1.21   1.69  0.56  1.74  0.89  \n",
      "222556  2.98  1.94  4.45   1.55  2.91  0.49  0.27  \n",
      "222557  3.77  3.57  1.07   1.86  0.37  0.32  0.32  \n",
      "222558  2.18  6.16  2.07   1.19  1.44  0.61  1.57  \n",
      "\n",
      "[37338 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'year' column to int (if not already) and filter the data frames\n",
    "df_tmax[\"year\"] = df_tmax[\"year\"].astype(int)\n",
    "df_tmax = df_tmax[(df_tmax[\"year\"] >= highest_min_year) & (df_tmax[\"year\"] <= lowest_max_year)]\n",
    "\n",
    "df_pcpn[\"year\"] = df_pcpn[\"year\"].astype(int)\n",
    "df_pcpn = df_pcpn[(df_pcpn[\"year\"] >= highest_min_year) & (df_pcpn[\"year\"] <= lowest_max_year)]\n",
    "\n",
    "print(\"Filtered df_tmax:\")\n",
    "print(df_tmax.head(100000))\n",
    "print(\"\\nFiltered df_pcpn:\")\n",
    "print(df_pcpn.head(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef84c4b",
   "metadata": {},
   "source": [
    "### Make seasonal temperature and precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a393d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing season temperature by year, state, county, and division:\n",
      "   year state county division  temp_gs\n",
      "0  1926    17    001       03    82.02\n",
      "1  1926    17    003       08    85.88\n",
      "2  1926    17    005       06    83.64\n",
      "3  1926    17    007       02    75.94\n",
      "4  1926    17    009       03    81.52\n",
      "\n",
      "Growing season precipitation by year, state, county, and division:\n",
      "   year state county division  pcpn_gs\n",
      "0  1926    17    001       03    29.75\n",
      "1  1926    17    003       08    16.78\n",
      "2  1926    17    005       06    21.48\n",
      "3  1926    17    007       02    25.96\n",
      "4  1926    17    009       03    30.54\n"
     ]
    }
   ],
   "source": [
    "# List of months for the growing season\n",
    "months = ['May', 'Jun', 'Jul', 'Aug', 'Sep']\n",
    "\n",
    "# --- Temperature Calculation ---\n",
    "# Convert the monthly temperature columns to numeric values\n",
    "df_tmax[months] = df_tmax[months].apply(pd.to_numeric, errors='coerce')\n",
    "# Compute the arithmetic mean (across the months) for each row\n",
    "df_tmax['temp_gs'] = df_tmax[months].mean(axis=1)\n",
    "# Group by year, state, county, and division to get one value per group\n",
    "df_temp_growing_season = df_tmax.groupby(\n",
    "    ['year', 'state', 'county', 'division']\n",
    ")['temp_gs'].mean().reset_index()\n",
    "\n",
    "print(\"Growing season temperature by year, state, county, and division:\")\n",
    "print(df_temp_growing_season.head())\n",
    "\n",
    "# --- Precipitation Calculation ---\n",
    "# Convert the monthly precipitation columns to numeric values\n",
    "df_pcpn[months] = df_pcpn[months].apply(pd.to_numeric, errors='coerce')\n",
    "# Compute the total precipitation (sum over the months) for each row\n",
    "df_pcpn['pcpn_gs'] = df_pcpn[months].sum(axis=1)\n",
    "# Group by year, state, county, and division to get one value per group\n",
    "df_precip_growing_season = df_pcpn.groupby(\n",
    "    ['year', 'state', 'county', 'division']\n",
    ")['pcpn_gs'].mean().reset_index()\n",
    "\n",
    "print(\"\\nGrowing season precipitation by year, state, county, and division:\")\n",
    "print(df_precip_growing_season.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0664bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing data\n"
     ]
    }
   ],
   "source": [
    "# Use the corn yield year range as the common complete years\n",
    "complete_years = set(range(highest_min_year, lowest_max_year + 1))\n",
    "\n",
    "# Get the unique (state, county) keys present in either temperature or precipitation datasets\n",
    "keys_temp = set(df_temp_growing_season.groupby([\"state\", \"county\"]).groups.keys())\n",
    "keys_pcpn = set(df_precip_growing_season.groupby([\"state\", \"county\"]).groups.keys())\n",
    "all_keys = keys_temp.union(keys_pcpn)\n",
    "\n",
    "missing_weather_report = {}\n",
    "\n",
    "for key in all_keys:\n",
    "    state, county = key\n",
    "    # Get years available from the temperature dataset for the county (if any)\n",
    "    years_temp = set(\n",
    "        df_temp_growing_season.loc[\n",
    "            (df_temp_growing_season[\"state\"] == state) & (df_temp_growing_season[\"county\"] == county),\n",
    "            \"year\"\n",
    "        ].astype(int).unique()\n",
    "    )\n",
    "    # Get years available from the precipitation dataset for the county (if any)\n",
    "    years_pcpn = set(\n",
    "        df_precip_growing_season.loc[\n",
    "            (df_precip_growing_season[\"state\"] == state) & (df_precip_growing_season[\"county\"] == county),\n",
    "            \"year\"\n",
    "        ].astype(int).unique()\n",
    "    )\n",
    "    \n",
    "    # Combine the available years from both data types\n",
    "    years_present = years_temp.union(years_pcpn)\n",
    "    missing_rows = sorted(complete_years - years_present)\n",
    "    \n",
    "    if missing_rows:\n",
    "        missing_weather_report[(state, county)] = missing_rows\n",
    "\n",
    "# Print the missing report in sorted order if any missing data exists, else print 'no missing data'\n",
    "if missing_weather_report:\n",
    "    for state, county in sorted(missing_weather_report.keys()):\n",
    "        print(f\"State {state}, County {county}:\")\n",
    "        print(f\"  Rows missing for years: {missing_weather_report[(state, county)]}\")\n",
    "else:\n",
    "    print(\"no missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece03b68",
   "metadata": {},
   "source": [
    "### Add data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff3ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year state county division_x                                   data_item  \\\n",
      "0  1926    17    001         03  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   \n",
      "1  1927    17    001         03  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   \n",
      "2  1928    17    001         03  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   \n",
      "3  1929    17    001         03  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   \n",
      "4  1930    17    001         03  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   \n",
      "\n",
      "   value  cv division_y  temp_gs division  pcpn_gs  \n",
      "0   38.0 NaN         03    82.02       03    29.75  \n",
      "1   30.0 NaN         03    80.06       03    18.06  \n",
      "2   41.0 NaN         03    80.68       03    18.21  \n",
      "3   31.0 NaN         03    80.20       03    23.11  \n",
      "4   29.0 NaN         03    85.78       03    11.83  \n"
     ]
    }
   ],
   "source": [
    "# Example: Load your dataframes (replace these with your actual file loading commands)\n",
    "# corn_yield_df = pd.read_csv(\"corn_yield.csv\")\n",
    "# df_temp_growing_season = pd.read_csv(\"temp_growing_season.csv\")\n",
    "# df_precip_growing_season = pd.read_csv(\"precip_growing_season.csv\")\n",
    "\n",
    "# Rename columns in corn_yield_df to match the keys in the other dataframes\n",
    "corn_yield_df = corn_yield_df.rename(columns={\n",
    "    'state_ansi': 'state',\n",
    "    'county_ansi': 'county',\n",
    "    'district_code': 'division'\n",
    "}).copy()\n",
    "\n",
    "# Ensure that the key columns 'state', 'county', and 'year' have the same data types\n",
    "# In this example, we'll convert 'state' and 'county' to string.\n",
    "for df in [corn_yield_df, df_temp_growing_season, df_precip_growing_season]:\n",
    "    df['state'] = df['state'].astype(str)\n",
    "    df['county'] = df['county'].astype(str)\n",
    "    # Assuming 'year' is consistent (e.g., int) between datasets; if not, convert as needed:\n",
    "    # df['year'] = df['year'].astype(int)\n",
    "\n",
    "# Merge corn_yield_df with the temperature dataframe using an outer join.\n",
    "merged_df = pd.merge(\n",
    "    corn_yield_df,\n",
    "    df_temp_growing_season,\n",
    "    on=['state', 'county', 'year'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Merge the resulting dataframe with the precipitation dataframe using an outer join.\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    df_precip_growing_season,\n",
    "    on=['state', 'county', 'year'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(merged_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c7bc6",
   "metadata": {},
   "source": [
    "#### Fix the triple division presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c77a5f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch found between division_x and division_y in some rows.\n",
      "     division_x division_y\n",
      "9702         08         09\n",
      "9703         08         09\n",
      "9704         08         09\n",
      "9705         08         09\n",
      "9706         08         09\n",
      "...         ...        ...\n",
      "9794         08         09\n",
      "9795         08         09\n",
      "9796         08         09\n",
      "9798         08         09\n",
      "9799         08         09\n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check only rows where division_x is not NaN\n",
    "mask = merged_df[\"division_x\"].notna()\n",
    "\n",
    "# Evaluate whether division_x equals division_y in those rows\n",
    "if (merged_df.loc[mask, \"division_x\"] == merged_df.loc[mask, \"division_y\"]).all():\n",
    "    print(\"All non-NaN division_x values match division_y.\")\n",
    "else:\n",
    "    print(\"Mismatch found between division_x and division_y in some rows.\")\n",
    "    # Optionally, print rows with mismatches for inspection:\n",
    "    mismatches = merged_df.loc[mask][merged_df.loc[mask, \"division_x\"] != merged_df.loc[mask, \"division_y\"]]\n",
    "    print(mismatches[[\"division_x\", \"division_y\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33412a63",
   "metadata": {},
   "source": [
    "After inspection of the df it was found that for state 17, county 199, the division is 08 for the yield data and 09 for the NOAA data. A quick inspection of the 'county-to-climdivs' and '240917_corn_yield_data' shows that this is the case from the start and not a coding error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74daa65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All non-NaN values in division_y match division.\n"
     ]
    }
   ],
   "source": [
    "# Check if all non-NaN values in division_y match division\n",
    "mask_div = merged_df[\"division_y\"].notna()\n",
    "\n",
    "if (merged_df.loc[mask_div, \"division_y\"] == merged_df.loc[mask_div, \"division\"]).all():\n",
    "    print(\"All non-NaN values in division_y match division.\")\n",
    "else:\n",
    "    print(\"Mismatch found between division_y and division in some rows.\")\n",
    "    mismatches = merged_df.loc[mask_div][\n",
    "        merged_df.loc[mask_div, \"division_y\"] != merged_df.loc[mask_div, \"division\"]\n",
    "    ]\n",
    "    print(mismatches[[\"division_y\", \"division\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5daf5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year state county division_yield division_noaa  \\\n",
      "0  1926    17    001             03            03   \n",
      "1  1927    17    001             03            03   \n",
      "2  1928    17    001             03            03   \n",
      "3  1929    17    001             03            03   \n",
      "4  1930    17    001             03            03   \n",
      "\n",
      "                                    data_item  value  cv  temp_gs  pcpn_gs  \n",
      "0  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   38.0 NaN    82.02    29.75  \n",
      "1  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   30.0 NaN    80.06    18.06  \n",
      "2  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   41.0 NaN    80.68    18.21  \n",
      "3  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   31.0 NaN    80.20    23.11  \n",
      "4  CORN, GRAIN - YIELD, MEASURED IN BU / ACRE   29.0 NaN    85.78    11.83  \n"
     ]
    }
   ],
   "source": [
    "# Assume merged_df is already created via prior merging steps\n",
    "\n",
    "# Create a copy of merged_df and work with the new DataFrame final_merged_df\n",
    "final_merged_df = merged_df.copy()\n",
    "\n",
    "# 1. Rename 'division_x' to 'division_yield'\n",
    "final_merged_df.rename(columns={'division_x': 'division_yield'}, inplace=True)\n",
    "\n",
    "# 2. Create new column 'division_noaa'\n",
    "# Since you've verified that division_y and division are essentially the same,\n",
    "# we fill from division_y and fallback to division if necessary.\n",
    "final_merged_df['division_noaa'] = final_merged_df['division_y'].fillna(final_merged_df['division'])\n",
    "\n",
    "# 3. Drop the now redundant columns 'division_y' and 'division'\n",
    "final_merged_df.drop(columns=['division_y', 'division'], inplace=True)\n",
    "\n",
    "# 4. Reorder columns so that 'division_noaa' is placed immediately after 'division_yield'\n",
    "cols = list(final_merged_df.columns)\n",
    "# Find index of 'division_yield'\n",
    "idx = cols.index('division_yield')\n",
    "# Build the new column order:\n",
    "new_cols = cols[:idx+1] + ['division_noaa'] + cols[idx+1:]\n",
    "# In case 'division_noaa' appears twice, remove duplicates while preserving order\n",
    "new_cols = list(dict.fromkeys(new_cols))\n",
    "final_merged_df = final_merged_df[new_cols]\n",
    "\n",
    "# Display the first few rows to verify the ordering\n",
    "print(final_merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab769a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'value', 'temp_gs', and 'pcpn_gs' columns are the same in both DataFrames: True\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to check\n",
    "cols_to_check = ['value', 'temp_gs', 'pcpn_gs']\n",
    "\n",
    "# Compare the corresponding columns between merged_df and final_merged_df\n",
    "are_equal = merged_df[cols_to_check].equals(final_merged_df[cols_to_check])\n",
    "print(\"The 'value', 'temp_gs', and 'pcpn_gs' columns are the same in both DataFrames:\", are_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e032329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to df_yield_weather.csv\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_merged_df is your final DataFrame that you want to save.\n",
    "# For example:\n",
    "# final_merged_df = merged_df  (after doing all your renaming/reordering)\n",
    "\n",
    "# Convert key columns to string to preserve leading zeros!!!!\n",
    "for col in ['county', 'division_yield', 'division_noaa']:\n",
    "    final_merged_df[col] = final_merged_df[col].astype(str)\n",
    "\n",
    "save_path = \"../02_data/corn_belt_2024_thesis/prepared_data/\"\n",
    "save_file = \"df_yield_weather.csv\"\n",
    "\n",
    "full_save_path = os.path.join(save_path, save_file)\n",
    "final_merged_df.to_csv(full_save_path, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "print(\"Data saved to df_yield_weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31696477",
   "metadata": {},
   "source": [
    "**Now please continue to the 'pre_modelling_diagnositcs' file**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b64b3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
